{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005dacc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from ngboost import NGBRegressor\n",
    "from scoringrules import crps_ensemble\n",
    "from ngboost.distns import Normal\n",
    "from ngboost.scores import CRPScore\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 1) Load\n",
    "X = pd.read_csv(\"Data/X_trn.csv\")\n",
    "y = pd.read_csv(\"Data/Y_trn.csv\").squeeze(\"columns\").astype(float).to_numpy().ravel()\n",
    "\n",
    "# 2) Feature groups\n",
    "num_cols = [\"year\", \"age\", \"prestg10\", \"childs\"]\n",
    "cat_cols = [\"occrecode\", \"wrkstat\", \"gender\", \"educcat\", \"maritalcat\"]\n",
    "\n",
    "# (optional) coerce numerics in case they were read as strings\n",
    "for c in num_cols:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "\n",
    "# 3) Preprocess: numeric imputation + dense one-hot for categoricals\n",
    "numeric = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),  # <-- dense OHE\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric, num_cols),\n",
    "        (\"cat\", categorical, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0.0,  # <-- ensure the whole output is dense\n",
    ")\n",
    "\n",
    "# 4) Model: preprocess -> NGBoost (natural gradients off)\n",
    "model = Pipeline([\n",
    "    (\"prep\", preprocessor),  # your SimpleImputer + OneHotEncoder(sparse_output=False)\n",
    "    (\"ngb\", NGBRegressor(\n",
    "        #Dist=Normal,\n",
    "        #Score=CRPScore,\n",
    "        random_state=42,\n",
    "        natural_gradient=False   # avoids the np.linalg.solve shape issue you hit earlier\n",
    "    )),\n",
    "])\n",
    "\n",
    "# 5) Split & fit\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6) Metrics: MSE, NLL\n",
    "prep = model.named_steps[\"prep\"]\n",
    "ngb  = model.named_steps[\"ngb\"]\n",
    "X_test_tx = prep.transform(X_test)  # dense ndarray\n",
    "\n",
    "y_point = ngb.predict(X_test_tx)\n",
    "y_dist  = ngb.pred_dist(X_test_tx)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_point)\n",
    "nll = -y_dist.logpdf(y_test).mean()\n",
    "print(\"Test MSE:\", float(mse))\n",
    "print(\"Test NLL:\", float(nll))\n",
    "\n",
    "# 7) CRPS from 1000 predictive samples per row\n",
    "n_samples = 100\n",
    "samples = y_dist.sample(n_samples)\n",
    "if hasattr(samples, \"detach\"):  # torch -> numpy if used\n",
    "    samples = samples.detach().cpu().numpy()\n",
    "samples = np.asarray(samples)\n",
    "\n",
    "# normalize shape to (n_obs, n_samples)\n",
    "if samples.shape == (n_samples, len(y_test)):\n",
    "    samples = samples.T\n",
    "elif samples.shape != (len(y_test), n_samples):\n",
    "    # fallback if .sample not present/behaves differently: assume Normal loc/scale\n",
    "    mu = np.asarray(getattr(y_dist, \"loc\"))\n",
    "    sigma = np.asarray(getattr(y_dist, \"scale\"))\n",
    "    rng = np.random.default_rng(42)\n",
    "    samples = mu[:, None] + sigma[:, None] * rng.standard_normal((mu.shape[0], n_samples))\n",
    "\n",
    "crps = crps_ensemble(y_test, samples).mean().item()\n",
    "print(\"Test CRPS:\", crps)\n",
    "\n",
    "print(\"Score class:\", ngb.Score.__name__)\n",
    "print(\"Dist class :\", ngb.Dist.__name__)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
